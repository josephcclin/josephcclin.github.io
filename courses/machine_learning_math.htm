<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Mathematics for Machine Learning</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<base target="_blank">
<link type="text/css" rel="stylesheet" href="../joseph.css">
<style type="text/css"> 
    td { text-align: center; padding:10px; width:30%; }
    #head { font-weight: bold; font-size:28px; text-align:left; margin-left:0px; }
    #sect { font-weight: bold; font-size:20px; }
</style>

</head>
<body background="../_themes/nature/nabkgnd.jpg" link="#0033CC" vlink="#8B4513">

<h1 id="head">Mathematics for Machine Learning</h1>
<br>
<blockquote>
&quot;<i>Think hard, not work hard.&quot; - Prof. R. C. T. Lee</i>
</blockquote>
<br>
<!--
<b><span style="font-size: 18px">Overview</span></b>
<br>
<br>
<span>
Course time: 10:10&#8211;11:00, Tuesday and 14:10&#8211;15:00 Wednesday.
<br>
 TA: Kuan-Hsun Tsou (鄒冠勲) (Room E814) 
<br>
Location: E416 (Tuesday) and E509 (Wednesday) at Main Engineering Building, Tamkang University.
</span>
<br>
<br>
-->
<b><span style="font-size: 18px">Textbooks and other reference material</span></b>
<br>
<UL type="square">
<li><i>Mathematics for Machine Learning.</i> Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong. Cambridge University Press. 2020. (<a href="https://mml-book.github.io">link to the book</a>)
<li><i>Elementary Linear Algebra - Applications Version. 12th Edition.</i> Howard Anton, Chris Rorres, Anton Kaul. 2019.
</UL>
<!--
<hr>
<br>
<b><span style="font-size: 18px">Textbooks</span></b>
<br>
-->
<!--
<UL type="square">
<li><i>Randomized Algorithms.</i> Motwani, R. and Raghavan, P., Cambridge University Press, 1995. 
<a href="http://www.amazon.com/gp/reader/0521474655/ref=sib_dp_pt/103-9654388-4263837#reader-link">
<span style="font-size: 12px">[cover]</span></a>
<li><i>Probability and Computing: Randomization and Probabilistic Techniques in Algorithms and Data Analysis. Second Edition.</i> 
M. Mitzenmacher and E. Upfal, Cambridge University Press, 2017. 
<a href="https://www.amazon.com/Probability-Computing-Randomization-Probabilistic-Techniques/dp/110715488X?fbclid=IwAR36C3BB9ctfqDgobqKvtJ3XnKhIZCqv2tavmc_L0v2gslAdbrOr4DcCGXU">
<span style="font-size: 12px">[cover]</span>
</UL>
<hr>
-->
<b><span style="font-size: 18px">Grading policy</span></b>
<UL>
<li> Attendance (10%)</li>
<li> Assignments + Quizzes (30%)</li>
<li> Midterm (30%)</li>
<li> Final Exam (30%)</li>
</UL>


<b><span style="font-size: 18px">Subjects we plan to cover</span></b>
<br>
<br>
<i>*We thank Prof. Deisenroth for permitting us to use the textbook pdf and figures in our lecture slides.</i>
<OL type=""1>
    <li>Course Introduction <a href="mml/ML_Math___Course_Introduction.pdf">[slides]</a></li>
    <li>Linear Algebra - Basis, Rank, Linear Mappings &amp; Affine Spaces <a href="mml/ML_Math___Linear_Algebra_Basis_Rank_Linear-Mappings_Affine-Spaces.pdf">[slides]</a> <!--, <a href="mml/hw_01.pdf">[exercise 01]</a>--></li> 
    <li>Linear Algebra - Norms, Inner Products &amp; Orthogonality <a href="mml/ML_Math___Linear_Algebra_Norms_Inner Products_Orthogonality.pdf">[slides]</a></li>
    <li>Linear Algebra - Projections &amp; Gram-Schmidt Orthogonalization <a href="mml/ML_Math___Linear_Algebra_Projections_Gram-Schmidt_Orthogonalization.pdf">[slides]</a></li>
    <li>Linear Algebra - Eigenvalues, Eigenvectors, Eigenspaces, Cholesky Decomposition &amp; Diagonalization <a href="mml/ML_Math___Linear_Algebra_Eigenvalues_Eigenvectors_Eigenspaces_Cholesky.pdf">[slides]</a><!--, <a href="mml/hw_02.pdf">[exercise 02]</a>--></li>
    <li>Linear Algebra - Singular Value Decomposition &amp; Matrix Approximation <a href="mml/ML_Math___Linear_Algebra_SVD_and_Matrix_Approximation.pdf">[slides]</a></li>
    <li>Vector Calculus - Differentiation, Partial Differentiation &amp; Gradients <a href="mml/ML_Math___Vector_Calculus_Differentiation_Partial Differentiation_and_Gradients.pdf">[slides]</a><!--, <a href="mml/hw_03.pdf">[exercise 03]</a>--></li>
    <li>Vector Calculus - Gradients of Vector-Valued Functions and Matrices <a href="mml/ML_Math___Vector_Calculus_Gradients_of_Vector-Valued_Functions_and_Matrices.pdf">[slides]</a><!--, <a href="mml/hw_04.pdf">[exercise 04]</a>--></li>
    <li>Vector Calculus - Backpropagation &amp; Automatic Differentiation <a href="mml/ML_Math___Vector_Calculus_Backpropagation_and_Automatic_Differentiation.pdf">[slides]</a></li>    
    <li>Vector Calculus - Linearization &amp; Multivariate Taylor Series <a href="mml/ML_Math___Vector_Calculus_Linearization_and_Multivariate_Taylor_Series.pdf">[slides]</a></li>    
    <li>Probability and Distributions - Sum Rule, Product Rule, Bayes' Theorem &amp; Summary Statistics <a href="mml/ML_Math___Probability_and_Distributions__SumRule_ProductRule_BayesTheorem_and_SummaryStatistics_.pdf">[slides]</a></li>
    <li>Probability and Distributions - Gaussian Distribution &amp; Change of Variables <a href="mml/ML_Math___Probability_and_Distributions__Gaussian_Distribution_and_ChangeOfVariables.pdf">[slides]</a><!--, <a href="mml/hw_05.pdf">[exercise 05]</a>--></li>
    <li>Continuous Optimization - Gradient Descent and Constrained Optimization <a href="mml/ML_Math___Continuous_Optimization_GradientDescent_and_Constrained_Optimization.pdf">[slides]</a></li>
    <li>Continuous Optimization - Preliminary Convex Optimization <a href="mml/ML_Math___Continuous_Optimization_Preliminary_Convex_Optimization.pdf">[slides]</a></li>
	<li>*Continuous Optimization - Policy Gradient Trick <a href="mml/ML_Math___PolicyGradientTrick.pdf">[slides]</a></li>
    <li>When Models Meet Data - Empirical Risk Minimization <a href="mml/ML_Math___Models_Meet_Data_Empirical_Risk_Minimization.pdf">[slides]</a></li>
    <li>When Models Meet Data - Maximum Likelihood Estimation &amp; Maximum A Posteriori Estimation <a href="mml/ML_Math___Models_Meet_Data_Parameter_Estimation.pdf">[slides]</a></li>
    <li>When Models Meet Data - Probabilistic Modeling &amp; Inference <a href="mml/ML_Math___Models_Meet_Data_Probabilistic_Modeling_and_Inference.pdf">[slides]</a></li>
    <li>Linear Regression - Maximum Likelihood Estimation &amp; Maximum A Posteriori Estimation <a href="mml/ML_Math___Linear_Regression_MLE_and_MAP.pdf">[slides]</a></li>
    <li>Gaussian Mixture Models <a href="mml/ML_Math___Gaussian_Mixture_Models.pdf">[slides]</a></li>
    <li>Expectation Maximization <a href="mml/ML_Math___Expectation_Maximization.pdf">[slides]</a></li>
    <li>Classification with Support Vector Machines <a href="mml/ML_Math___Support_Vector_Machine.pdf">[slides]</a></li>
</OL>


<!--
<b><span style="font-size: 18px">Examinations</span></b>
<br>
<UL>
    <li> Midterm Exam <a href="mml/midterm_mml_2023_fall.pdf">[pdf]</a></li>
    <li> Final Exam <a href="mml/final_exam_2023_Fall.pdf">[pdf]</a></li>
</UL>
-->    

<!-- 
<b><span style="font-size: 18px">Assignments</span></b>
<UL>
<li>Assignment 1 &nbsp; (due date: 11 March 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_01.pdf">pdf</a>]</span>
<li>Assignment 2 &nbsp; (due date: 18 March 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_02.pdf">pdf</a>]</span>
<li>Assignment 3 &nbsp; (due date: 8 April 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_03.pdf">pdf</a>]</span>
<li>Assignment 4 &nbsp; (due date: 15 April 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_04.pdf">pdf</a>]</span>
<li>Assignment 5 &nbsp; (due date: 7 May 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_05.pdf">pdf</a>]</span>
<li>Assignment 6 &nbsp; (due date: 14 May 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_06.pdf">pdf</a>]</span>
<li>Assignment 7 &nbsp; (due date: 21 May 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_07.pdf">pdf</a>]</span>
<li>Assignment 8 &nbsp; (due date: 28 May 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_08.pdf">pdf</a>]</span>
<li>Assignment 9 &nbsp; (due date: 4 June 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_09.pdf">pdf</a>]</span>
<li>Assignment 10 &nbsp; (due date: 11 June 2021)
<span style="font-size: 12px">[<a href="linear_algebra/assignments/hw_10.pdf">pdf</a>]</span>
</UL>
-->

<hr>
<br>

<b><span style="font-size: 18px">Exercises</span></b>
<br>
<UL type="square">
<li>Assignment 01 [<a href="mml/assignment_01.pdf">pdf</a>]</li>
<li>Assignment 02 [<a href="mml/assignment_02.pdf">pdf</a>]</li>
</UL>
<hr>


<!-- 
<b><span style="font-size: 18px">Exams</span></b>
<UL>
<li>Midterm Exam &nbsp; (20 April 2021) [<a href="linear_algebra/midterm.pdf">pdf</a>]
<li>Final Exam &nbsp; (15 June 2021) [<a href="linear_algebra/final_exam.pdf">pdf</a>]
</UL>
<br>
<br>
-->


<span style="color: #777777">
<i>
Any question is welcome. <br>
Please contact Joseph, Chuang-Chieh Lin</i> (<i>Email to</i>: <i><a href="mailto:josephcclin@mail.ntou.edu.tw">
josephcclin_AT_MAIL_NTOU_EDU.TW</a></i>)
</span>
<br>
<hr align="center">
<p style="text-align: center; font-size: 12px; color: #BBBBBB">
<!-- Copyright -->&#169; 2004 Joseph Chuang-Chieh Lin <!--, CSIE National Chung Cheng University, ALL RIGHTS RESERVED -->
</p>

</body>    
</html>
